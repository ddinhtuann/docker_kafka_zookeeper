version: '2'
services:
  zookeeper:
    image: zookeeper:3.5
    hostname: zookeeper
    container_name: zookeeper
    logging:
      options:
        max-size: "10m"
        max-file: "3"
    restart: always
    ports:
      - "2181:2181"

    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - default

  broker:
    image: confluentinc/cp-server:6.0.1
    hostname: broker
    container_name: broker
    logging:
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      - zookeeper
    restart: always
    ports:
      - "9092:9092"
      - "9101:9101"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: '10.0.68.37:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://10.0.68.37:29092,PLAINTEXT_HOST://10.0.68.37:9092
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: 10.0.68.37
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://10.0.68.37:28081
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: 10.0.68.37:29092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'

    volumes:
      - /home/adminct/Tuanvd/docker_kafka_zookeeper/data:/etc/kafka/secrets
    networks:
      - default

  # schema-registry:
  #   image: confluentinc/cp-schema-registry:6.0.1
  #   hostname: schema-registry
  #   container_name: schema-registry
  #     logging:
  #     options:
  #       max-size: "10m"
  #       max-file: "3"
  #   restart: always
  #   depends_on:
  #     - broker
  #   ports:
  #     - "28081:8081"
  #   environment:
  #     SCHEMA_REGISTRY_HOST_NAME: schema-registry
  #     SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: '10.0.68.37:29092,10.0.68.103:29092,10.0.68.100:29092'
  #     SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
  #   networks:
  #     - default

  # connect:
  #   image: confluentinc/cp-kafka-connect-base:6.0.1
  #   hostname: connect
  #   container_name: kafka-connect
  #   logging:
  #     options:
  #       max-size: "10m"
  #       max-file: "3"
  #   restart: always
  #   depends_on:
  #     - broker
  #     - schema-registry
  #   ports:
  #     - "28083:8083"
  #   environment:
  #     CONNECT_BOOTSTRAP_SERVERS: '10.0.68.37:29092,10.0.68.103:29092,10.0.68.100:29092'
  #     CONNECT_REST_ADVERTISED_HOST_NAME: connect
  #     CONNECT_REST_PORT: 8083
  #     CONNECT_GROUP_ID: kafka-connect
  #     CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
  #     CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
  #     CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
  #     CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
  #     CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
  #     CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
  #     CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://10.0.68.37:28081
  #     # CLASSPATH required due to CC-2422
  #     CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-6.0.1.jar
  #     CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
  #     CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
  #     CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
  #     CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
  #     #CONNECT_PLUGIN_PATH: /usr/share/java, /usr/share/confluent-hub-components, /data/connect-jars
  #   volumes:
  #       - $PWD/connect_data:/data
  #   networks:
  #     - default

  kafka_manager:
    image: kafkamanager/kafka-manager:3.0.0.4
    container_name: kafka_manager
    logging:
      options:
        max-size: "10m"
        max-file: "3"
    restart: always
    logging:
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "9001:9000"
    environment:
      ZK_HOSTS: "10.0.68.37:2181"
      APPLICATION_SECRET: "random-secret"
    # command: -Dpidfile.path=/dev/null
    networks:
      - default
            
  # control-center:
  #   image: confluentinc/cp-enterprise-control-center:6.0.1
  #   hostname: control-center
  #   container_name: control-center
  #   logging:
  #     options:
  #       max-size: "10m"
  #       max-file: "3"
  #   restart: always
  #   depends_on:
  #     - broker
  #     - schema-registry
  #     - connect
  #   ports:
  #     - "9021:9021"
  #   environment:
  #     CONTROL_CENTER_BOOTSTRAP_SERVERS: '10.0.68.37:29092,10.0.68.103:29092,10.0.68.100:29092'
  #     CONTROL_CENTER_CONNECT_CLUSTER: '10.0.68.37:28083,10.0.68.103:28083,10.0.68.100:28083'
  #     #CONTROL_CENTER_KSQL_KSQLDB1_URL: "http://ksqldb-server:8088"
  #     #CONTROL_CENTER_KSQL_KSQLDB1_ADVERTISED_URL: "http://localhost:8088"
  #     CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://10.0.68.37:28081"
  #     CONTROL_CENTER_REPLICATION_FACTOR: 1
  #     CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
  #     CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
  #     CONFLUENT_METRICS_TOPIC_REPLICATION: 1
  #     PORT: 9021
  #   networks:
  #     - default

  # logstash-7.9.0:
  #   image: 164425/docker_logstash-7.9.0
  #   container_name: logstash-7.9.0
  #   logging:
  #     options:
  #       max-size: "10m"
  #       max-file: "3"
  #   restart: always
  #   ports:
  #    - 5044:5044
  #    - 9600:9600
  #   volumes:
  #    - /home/adminct/Tuanvd/docker_logtash-7.9.0/logstash-7.9.0/config/logstash-sample.conf:/usr/share/logstash/config/logstash-sample.conf
  #    - /home/adminct/Tuanvd/docker_logtash-7.9.0/logstash-7.9.0/config/logstash.yml:/usr/share/logstash/config/logstash.yml
  #    - /home/adminct/Tuanvd/docker_logtash-7.9.0/logstash-7.9.0/config/pipelines.yml:/usr/share/logstash/config/pipelines.yml
  #   command:
  #    - USER root
  #    - RUN yum install -y vim
  #    - CMD 

networks:
  default:
    name: zk-network
    external: true
